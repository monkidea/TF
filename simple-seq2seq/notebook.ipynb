{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import data, data_utils\n",
    "import importlib as I\n",
    "#I.reload(data_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ctl, idx_words, idx_phonemes = data.load_data()\n",
    "(trainX, trainY), (testX, testY), (validX, validY) = data_utils.split_dataset(idx_phonemes, idx_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters \n",
    "xseq_len = trainX.shape[-1]\n",
    "yseq_len = trainY.shape[-1]\n",
    "batch_size = 128\n",
    "xvocab_size = len(data_ctl['idx2pho'].keys())  # 27\n",
    "yvocab_size = len(data_ctl['idx2alpha'].keys())  # 70\n",
    "emb_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc_ip = [ tf.placeholder(dtype=tf.int32,\n",
    "                       shape = (None,),\n",
    "                       name = 'ei_{}'.format(i)) for i in range(xseq_len) ]\n",
    "# alternatively\n",
    "#  enc_ip = tf.placeholder(shape=[None,xseq_len], dtype=tf.int32, name='enc_ip')\n",
    "labels = [ tf.placeholder(dtype=tf.int32,\n",
    "                       shape = (None,),\n",
    "                       name = 'ei_{}'.format(i)) for i in range(yseq_len) ]\n",
    "# alternatively\n",
    "#  labels = tf.placeholder(shape=[None,yseq_len], dtype=tf.int32, name='labels')\n",
    "dec_ip = [ tf.zeros_like(enc_ip[0], dtype=tf.int32, name='GO')] + labels[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "basic_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "        tf.nn.rnn_cell.BasicLSTMCell(emb_dim, state_is_tuple=True),\n",
    "        output_keep_prob=keep_prob)\n",
    "stacked_lstm = tf.nn.rnn_cell.MultiRNNCell([basic_cell]*3, state_is_tuple=True)\n",
    "\n",
    "\n",
    "with tf.variable_scope('decoder') as scope:\n",
    "    decode_outputs, decode_states = tf.nn.seq2seq.embedding_rnn_seq2seq(enc_ip,dec_ip, stacked_lstm,\n",
    "                                        xvocab_size, yvocab_size, emb_dim)\n",
    "    scope.reuse_variables()\n",
    "    # testing\n",
    "    decode_outputs_test, decode_states_test = tf.nn.seq2seq.embedding_rnn_seq2seq(\n",
    "        enc_ip, dec_ip, stacked_lstm, xvocab_size, yvocab_size,emb_dim,\n",
    "        feed_previous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we weight the losses based on timestep of decoder output\n",
    "loss_weights = [tf.ones_like(l, dtype=tf.float32) for l in labels] # gives [1, 1, ..., 1,1] - equal weights\n",
    "loss = tf.nn.seq2seq.sequence_loss(decode_outputs, labels, loss_weights, yvocab_size)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feed(X, Y):\n",
    "    feed_dict = {enc_ip[t]: X[t] for t in range(xseq_len)}\n",
    "    feed_dict.update({labels[t]: Y[t] for t in range(yseq_len)})\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    # create a generator\n",
    "    train_batch_gen = data_utils.batch_gen(trainX, trainY, batch_size)\n",
    "    X, Y = train_batch_gen.__next__()\n",
    "    feed_dict = get_feed(X, Y)\n",
    "    feed_dict[keep_prob] = 0.5\n",
    "    _, out = sess.run([train_op, loss], feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rtest_batch_gen = data_utils.rand_batch_gen(testX, testY, batch_size)\n",
    "for i in range(10):\n",
    "    batchX, batchY = rtest_batch_gen.__next__()\n",
    "    print(i,batchX[40], batchY[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_utils.decode_word(batchX[12], data_ctl['idx2alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_utils.decode_phonemes(batchY[12], data_ctl['idx2pho'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_batch(train_batch_gen):\n",
    "    # get batches\n",
    "    batchX, batchY = train_batch_gen.__next__()\n",
    "    # build feed\n",
    "    feed_dict = get_feed(batchX, batchY)\n",
    "    feed_dict[keep_prob] = 0.5\n",
    "    _, loss_v = sess.run([train_op, loss], feed_dict)\n",
    "    return loss_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_step(eval_batch_gen):\n",
    "    # get batches\n",
    "    batchX, batchY = eval_batch_gen.__next__()\n",
    "    # build feed\n",
    "    feed_dict = get_feed(batchX, batchY)\n",
    "    feed_dict[keep_prob] = 1.\n",
    "    loss_v, dec_op_v = sess.run([loss, decode_outputs_test], feed_dict)\n",
    "    # dec_op_v is a list; also need to transpose 0,1 indices\n",
    "    dec_op_v = np.array(dec_op_v).transpose([1,0,2])\n",
    "    return loss_v, dec_op_v, batchX, batchY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_batch(eval_batch_gen, num_batches):\n",
    "    losses, predict_loss = [], []\n",
    "    for i in range(num_batches):\n",
    "        loss_v, dec_op_v, batchX, batchY = eval_step(eval_batch_gen)\n",
    "        losses.append(loss_v)\n",
    "        for j in range(len(dec_op_v)):\n",
    "            real = batchX.T[j]\n",
    "            predict = np.argmax(dec_op_v, axis=2)[j]\n",
    "            predict_loss.append(all(real == predict))\n",
    "    return np.mean(losses), np.mean(predict_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    batchX, batchY = train_batch_gen.__next__()\n",
    "    feed_dict = get_feed(batchX, batchY)\n",
    "    feed_dict[keep_prob] = 1.\n",
    "    loss_v, dec_op_val = sess.run([loss, decode_outputs_test], feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dec_op_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_batch_gen = data_utils.rand_batch_gen(trainX, trainY, batch_size)\n",
    "a,b = train_batch_gen.__next__()\n",
    "print(a.shape,b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-0ade50e99980>:6 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "\n",
      "Iteration #0\n",
      "val   loss : 3.255979061126709\n",
      "train loss : 3.2577998638153076\n",
      "\n",
      "Iteration #5000\n",
      "val   loss : 0.6567713022232056\n",
      "train loss : 0.6086580753326416\n",
      "\n",
      "Iteration #10000\n",
      "val   loss : 0.4550465941429138\n",
      "train loss : 0.38915368914604187\n",
      "\n",
      "Iteration #15000\n",
      "val   loss : 0.30922865867614746\n",
      "train loss : 0.3227866291999817\n",
      "\n",
      "Iteration #20000\n",
      "val   loss : 0.32482245564460754\n",
      "train loss : 0.2962823212146759\n",
      "\n",
      "Iteration #25000\n",
      "val   loss : 0.2795450687408447\n",
      "train loss : 0.2243996113538742\n",
      "\n",
      "Iteration #30000\n",
      "val   loss : 0.2611120045185089\n",
      "train loss : 0.23757104575634003\n",
      "\n",
      "Iteration #35000\n",
      "val   loss : 0.2358589470386505\n",
      "train loss : 0.19370242953300476\n",
      "\n",
      "Iteration #40000\n",
      "val   loss : 0.2391183078289032\n",
      "train loss : 0.18203002214431763\n",
      "\n",
      "Iteration #45000\n",
      "val   loss : 0.20033389329910278\n",
      "train loss : 0.15348316729068756\n",
      "\n",
      "Iteration #50000\n",
      "val   loss : 0.24642911553382874\n",
      "train loss : 0.1512463390827179\n",
      "interrupted by user at 53221\n"
     ]
    }
   ],
   "source": [
    "val_batch_gen = data_utils.rand_batch_gen(validX, validY, 16)\n",
    "train_eval_batch_gen = data_utils.rand_batch_gen(trainX, trainY, 16)\n",
    "train_batch_gen = data_utils.rand_batch_gen(trainX, trainY, 128)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(100000):\n",
    "    try:\n",
    "        train_batch(train_batch_gen)\n",
    "        if i % 5000 == 0:\n",
    "            val_loss, val_predict = eval_batch(val_batch_gen, 16)\n",
    "            train_loss, train_predict = eval_batch(train_eval_batch_gen, 16)\n",
    "            print('\\nIteration #{}'.format(i))\n",
    "            print('val   loss : {}'.format(val_loss))\n",
    "            print('train loss : {}'.format(train_loss))\n",
    "\n",
    "            #print(\"val loss   : {0}, val predict   = {1}%\".format(val_loss, val_predict * 100))\n",
    "            #print(\"train loss : {0}, train predict = {1}%\".format(train_loss, train_predict * 100))\n",
    "\n",
    "            sys.stdout.flush()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"interrupted by user at {}\".format(i))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch_gen = data_utils.rand_batch_gen(testX, testY, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_loss, output, X, Y = eval_step(test_batch_gen)\n",
    "model_op = np.argmax(output, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pronunciation           real spelling        model spelling      \n",
      "\n",
      "MAH0KLAE1NAH0HHAE0N     mcclanahan           mcclanahan          \n",
      "BAH1NDAH0SWEH2R         bundeswehr           bundessware         \n",
      "IH0NRIY1KWEH0Z          enriquez             enriques            \n",
      "LOW0NEH1ROW0            lonero               lonero              \n",
      "BEH1NAH0VIY0DEH0S       benevides            benevedese          \n",
      "DIH0STRAH1KTIH0V        destructive          distructive         \n",
      "CHAO1NCHUW0LIY0         cianciulli           chonchully          \n",
      "PRAA2KLAH0MEY1SHAH0NZ   proclamations        proclamations       \n",
      "FRIY1THIH1NGKER0        freethinker          freethinker         \n",
      "KAH0NTEH1MPTAH0BAH0L    contemptible         contemptable        \n",
      "PRIY1SKUW2LER0          preschooler          prescouler          \n",
      "TOW2MIY0IY1CHIY0        tomiichi             tomiacio            \n",
      "PAA1STAH0L              postle               postel              \n",
      "GUW2SIY0AO1RAH0         gusciora             gusiora             \n",
      "STAE1GNEY2TIH0NG        stagnating           stagnating          \n",
      "TER1MIH0NAY2            termini              turmini             \n"
     ]
    }
   ],
   "source": [
    "print('{0: <23} {1: <20} {2: <20}\\n'.format('pronunciation','real spelling','model spelling'))\n",
    "for i in range(len(X)):\n",
    "    pronounce = data_utils.decode_word(X.T[i], data_ctl['idx2pho'])\n",
    "    real_spell = data_utils.decode_phonemes( Y.T[i], data_ctl['idx2alpha'])\n",
    "    model_spell = data_utils.decode_phonemes(model_op[i], data_ctl['idx2alpha'])\n",
    "    print('{0: <23} {1:<19}  {2:<20}'.format(pronounce, real_spell[::2], model_spell[::2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
