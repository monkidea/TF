{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./MNIST_data/',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 25\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network params\n",
    "n_hid1 = 256\n",
    "n_hid2 = 256\n",
    "n_input = 784 # pixels\n",
    "n_output = 10 # classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input to graph\n",
    "x = tf.placeholder(tf.float32,[None,n_input])\n",
    "y = tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collection of weights and biases\n",
    "weights = {\n",
    "    'h1' : tf.Variable(tf.random_normal([n_input,n_hid1])),\n",
    "    'h2' : tf.Variable(tf.random_normal([n_hid1,n_hid2])),\n",
    "    'out' : tf.Variable(tf.random_normal([n_hid2,n_output])),\n",
    "}\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random_normal([n_hid1])),\n",
    "    'b2' : tf.Variable(tf.random_normal([n_hid2])),\n",
    "    'out' : tf.Variable(tf.random_normal([n_output])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "def mlp(X,w,b):\n",
    "    layer1 = tf.nn.relu( tf.matmul(X,w['h1']) + b['b1'])\n",
    "    layer2 = tf.nn.relu( tf.matmul(layer1,w['h2']) + b['b2'])\n",
    "    return tf.matmul(layer2,w['out']) + b['out']   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activation = mlp(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(activation,y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration :  0\n",
      "loss :  161.71771238\n",
      "iteration :  1\n",
      "loss :  40.7077896569\n",
      "iteration :  2\n",
      "loss :  25.3307529456\n",
      "iteration :  3\n",
      "loss :  17.4956130979\n",
      "iteration :  4\n",
      "loss :  12.5986237408\n",
      "iteration :  5\n",
      "loss :  9.38749273018\n",
      "iteration :  6\n",
      "loss :  6.96301994625\n",
      "iteration :  7\n",
      "loss :  5.12692543847\n",
      "iteration :  8\n",
      "loss :  3.74818487188\n",
      "iteration :  9\n",
      "loss :  2.71242641489\n",
      "iteration :  10\n",
      "loss :  2.05221981702\n",
      "iteration :  11\n",
      "loss :  1.47914119526\n",
      "iteration :  12\n",
      "loss :  1.11216822273\n",
      "iteration :  13\n",
      "loss :  0.790469292926\n",
      "iteration :  14\n",
      "loss :  0.598892657591\n",
      "iteration :  15\n",
      "loss :  0.432035042307\n",
      "iteration :  16\n",
      "loss :  0.308667711172\n",
      "iteration :  17\n",
      "loss :  0.258233316828\n",
      "iteration :  18\n",
      "loss :  0.19374179872\n",
      "iteration :  19\n",
      "loss :  0.175091901182\n",
      "iteration :  20\n",
      "loss :  0.183430864642\n",
      "iteration :  21\n",
      "loss :  0.164646749322\n",
      "iteration :  22\n",
      "loss :  0.125897945247\n",
      "iteration :  23\n",
      "loss :  0.110157037738\n",
      "iteration :  24\n",
      "loss :  0.126236017074\n",
      "Accuracy :  0.9543\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    num_batches = mnist.train.num_examples // batch_size\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_loss = 0\n",
    "        for j in range(num_batches):\n",
    "            batchX,batchY = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer,{x:batchX,y:batchY})\n",
    "            avg_loss += sess.run(loss,{x:batchX,y:batchY})\n",
    "        \n",
    "        print 'iteration : ',epoch\n",
    "        print 'loss : ',avg_loss/num_batches\n",
    "        \n",
    "    correct_pred = tf.equal(tf.argmax(activation,1),tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred,'float'))\n",
    "    \n",
    "    print 'Accuracy : ', sess.run(accuracy,{x:mnist.test.images,y:mnist.test.labels})\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
